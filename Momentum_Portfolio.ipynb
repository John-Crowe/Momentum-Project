{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Momentum Portfolio\n",
    "\n",
    "For this momentum portfolio project, I will be using CRSP stock data to replicate the momentum decile returns in the 2016 paper, \"Momentum Crashes\" by Daniel and Moskowitz. The objective of this project is to determine the average annual returns for 10 different momentum portfolio deciles. Each decile categorizes every stock based on the total return for the last year of each stock. The bottom decile stocks provided the worst returns for the past year and the top deciles were the top performers of the past year. We also create the momentum portfolio outlined by Ken French (KRF) and compare it's returns to that of the Daniel and Moskowitz (DM) portfolio.\n",
    "\n",
    "The risk free rate is from the French Fama numbers (not CRSP), which I download below. I combine the dlret and ret data for the stocks and create a new 'ret' column to encompass all returns for the stocks. I filter the stocks to only use the 10 and 11 sharecodes and the 1, 2 and 3 exchanges, per the French Fama website. \n",
    "\n",
    "Below is a list of the libraries I used for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrds\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "import pandas_datareader\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc331054",
   "metadata": {},
   "source": [
    "Below I connected the script to the “WRDS” servers so I could access the data for the stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your WRDS username [John]:johncrowe\n",
      "Enter your password:········\n",
      "WRDS recommends setting up a .pgpass file.\n",
      "Create .pgpass file now [y/n]?: y\n",
      "Created .pgpass file successfully.\n",
      "You can create this file yourself at any time with the create_pgpass_file() function.\n",
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "id = 'johncrowe'\n",
    "conn = wrds.Connection(id)\n",
    "\n",
    "# Download monthly crsp stock data\n",
    "a = conn.raw_sql(\"\"\"\n",
    "                    select a.permno, a.permco, a.date, b.shrcd, b.exchcd,\n",
    "                    a.ret, a.retx, a.shrout, a.prc, a.cfacshr, a.cfacpr\n",
    "                    from crspq.msf as a \n",
    "                    left join crsp.msenames as b\n",
    "                    on a.permno=b.permno\n",
    "                    and b.namedt<=a.date\n",
    "                    and a.date<=b.nameendt\n",
    "                    where a.date between '01/01/1900' and '12/31/2023'\n",
    "                    \"\"\")\n",
    "\n",
    "# Download monthly crsp delisted stock data\n",
    "b = conn.raw_sql(\"\"\"\n",
    "                    select permno, dlret, dlstdt, dlstcd\n",
    "                    from crspq.msedelist\n",
    "                    \"\"\")\n",
    "\n",
    "c = conn.get_table(library='ff', table='factors_monthly')\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d14e44",
   "metadata": {},
   "source": [
    "Below we create new dataframes so that we do not have to reconnect to the SQL servers to rerun our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03894394",
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_raw = a.copy()\n",
    "dlret_raw = b.copy()\n",
    "french = c.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2c1c2c",
   "metadata": {},
   "source": [
    "Below we are importing data for the monthly risk free rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d20e45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange french data\n",
    "french = french[['date','mktrf','smb','hml','rf']]\n",
    "french['mkt'] = french['mktrf'] + french['rf']\n",
    "french['date'] = pd.to_datetime(french['date']) + MonthEnd(0)\n",
    "\n",
    "# Change columns to floats\n",
    "french['mktrf'] = french['mktrf'].astype(float)\n",
    "french['smb'] = french['smb'].astype(float)\n",
    "french['hml'] = french['hml'].astype(float)\n",
    "french['rf'] = french['rf'].astype(float)\n",
    "\n",
    "# Create year and month columns for french data\n",
    "french['year'] = french['date'].dt.year\n",
    "french['month'] = french['date'].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a12b1f",
   "metadata": {},
   "source": [
    "Here we use some data cleaning and rearraning. First we arrange by date and permno, then we manipulate the date portion so that we can ensure they are in the proper order and then merge delisted with crsp to create our total return column, which we will call 'ret'. We then attach the lagged market return and end up with a row in our dataframe for each stock-year-month. The market equity can be found by multiply the number of shares outstanding 'shrout' by price per share 'prc'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ee4606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean crsp_raw data\n",
    "crsp_raw = crsp_raw.sort_values(['permno','date']).reset_index(drop=True).copy()\n",
    "crsp_raw[['permno', 'permco']] = crsp_raw[['permno', 'permco']].astype(int)\n",
    "crsp_raw['date'] = pd.to_datetime(crsp_raw['date'], format='%y-%m-%d') + MonthEnd(0)\n",
    "crsp_raw['prc'] = np.absolute(crsp_raw['prc'])\n",
    "\n",
    "# Clean dlret_raw data\n",
    "dlret_raw = dlret_raw.sort_values(['permno', 'dlstdt']).reset_index(drop=True).copy()\n",
    "dlret_raw.permno = dlret_raw.permno.astype(int)\n",
    "dlret_raw['dlstdt'] = pd.to_datetime(dlret_raw['dlstdt'])\n",
    "dlret_raw['date'] = dlret_raw['dlstdt'] + MonthEnd(0)\n",
    "\n",
    "# Merge crsp_raw with dlret_raw\n",
    "stocks = crsp_raw.merge(dlret_raw[['permno','date','dlret']], how='outer', on=['permno','date'])\n",
    "stocks['dlret'] = stocks['dlret'].fillna(0)\n",
    "stocks['shrcd'] = stocks['shrcd'].ffill()\n",
    "stocks['exchcd'] = stocks['exchcd'].ffill()\n",
    "stocks['ret'] = stocks['ret'].fillna(0)\n",
    "stocks['prc'] = stocks['prc'].fillna(0)\n",
    "stocks['shrout'] = stocks['shrout'].fillna(0)\n",
    "stocks['me'] = stocks['prc']*stocks['shrout']\n",
    "\n",
    "# Redefine 'ret' to include delisted return\n",
    "stocks['ret'] = (1 + stocks['ret']) * (1 + stocks['dlret']) - 1\n",
    "\n",
    "# Attach Lagged Market Equity (to be used as weights) for each stock-year-month\n",
    "stocks = stocks.sort_values(by=['permno','date']).reset_index().drop('index',axis=1).copy()\n",
    "stocks['daten'] = stocks['date'].dt.year*12 + stocks['date'].dt.month\n",
    "stocks['IsValidLag'] = stocks['daten'].diff(1) == 1 # Lag date has to be the lagged date\n",
    "stocks.loc[stocks[stocks['permno'].diff(1) != 0].index,['IsValidLag']] = False # Lagged date has to be the same security\n",
    "stocks['lme'] = stocks[['permno','me']].groupby('permno').shift(1)\n",
    "stocks.loc[stocks[stocks['IsValidLag'] == False].index,['lme']] = np.nan\n",
    "stocks = stocks.drop(['IsValidLag','daten'], axis=1)\n",
    "\n",
    "# Filter for 'shrcd' = 10 or 11 and 'exchcd' = 1, 2 or 3 per the Fama French website\n",
    "stocks = stocks[((stocks['shrcd'] == 10) | (stocks['shrcd'] == 11)) & ((stocks['exchcd'] == 1) | (stocks['exchcd'] == 2) | (stocks['exchcd'] == 3))].copy()\n",
    "\n",
    "# Create year and month columns for readability\n",
    "stocks['year'] = stocks['date'].dt.year\n",
    "stocks['month'] = stocks['date'].dt.month\n",
    "\n",
    "# Rearrange columns into desired format\n",
    "stocks = stocks[['permno', 'year', 'month', 'exchcd', 'prc', 'shrout', 'lme', 'ret']]\n",
    "\n",
    "# Drop NAs so that columns without lagged market equity value are not included\n",
    "stocks = stocks.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5ef9f3",
   "metadata": {},
   "source": [
    "In the below function momentum_ranking, I iterate through every month present in our stock data and find the last 12 months of returns for each stock. Next, I only consider the stocks that existed continuously for the last 13 months (current month plus last 12 months). I do this so we do not have stocks with missing data for this time period that could cause errors in the code because this method is easily replicable in real life. While Daniel and Moskowitz also considered utilizing stocks that were present in month $t-12$ plus another 7 different months plus month $t-1$, I found this to make an extremely small impact on our results. Therefore, we only considered stocks that existed for all of the previous 13 months. I then summed all of the stock returns for months $t-12$ to $t-2$, giving us 11 months of return data. I did not include data for month $t-1$, per direction from Daniel and Moskowitz. I then ranked all stocks, with 1 being the lowest return and a higher ranking corresponding to a higher return. Every month, each stock will get a new ranking, so our output will be for every stock-month-year.\n",
    "\n",
    "The final output is from 1927-2023, with a row for every year-month-stock. We are just calculating total returns and not factoring in the risk free rate to determine excess returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ab40cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum_ranking(df):\n",
    "    \n",
    "    # Initialize final dataframe\n",
    "    final_df = pd.DataFrame()\n",
    "    \n",
    "    # First let's create a list containing our dates, so we can find the last 13 months of data for momentum\n",
    "    date = df[['year', 'month']].drop_duplicates().sort_values(by=['year', 'month'])\n",
    "    df['daten'] = df['year']*12 + df['month']\n",
    "    \n",
    "    # Iterate through all available year-months for stock data\n",
    "    for index, row in date.iterrows():\n",
    "        \n",
    "        year = row['year']\n",
    "        month = row['month']\n",
    "        daten = year*12 + month\n",
    "        \n",
    "        # Filter for all stock-year-months from 12 months ago to current year-month\n",
    "        momentum_stocks = df[(df['daten'] <= daten) & (df['daten'] >= daten - 12)].copy()\n",
    "\n",
    "        # Next filter for the stocks present in all of the previous 13 months\n",
    "        counts = momentum_stocks['permno'].value_counts()\n",
    "        valid_permnos = counts[counts == 13].index\n",
    "        momentum_stocks = momentum_stocks[momentum_stocks['permno'].isin(valid_permnos)].copy()\n",
    "\n",
    "        # Divide momentum stock past data (t-12 to t-2) from present data (t) and dropping one month lag (t-1) \n",
    "        present = momentum_stocks[momentum_stocks['daten'] == daten]\n",
    "        past = momentum_stocks[momentum_stocks['daten'] <= daten - 2].copy()\n",
    "        ret_by_permno = past.groupby('permno')['ret'].sum().reset_index()\n",
    "        ret_by_permno.columns = ['permno', '11_month_ret']\n",
    "            \n",
    "        # Merge the past stock info with present to attach the 11_month_ret column to the momentum stocks\n",
    "        present = present.merge(ret_by_permno, on='permno', how='inner')\n",
    "        present['ranking_ret'] = present['11_month_ret'].rank(ascending=True)\n",
    "\n",
    "        # Reorder columns into desired format\n",
    "        present = present[['year', 'month', 'permno', 'exchcd', 'lme', 'ret', 'ranking_ret']]\n",
    "            \n",
    "        # Add this month data frame to final dataframe\n",
    "        final_df = pd.concat([final_df, present])\n",
    "        \n",
    "    return(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e87480bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a1 = momentum_ranking(stocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815cf8d8",
   "metadata": {},
   "source": [
    "For Daniel and Moskowitz, we have the following information for momentum decile classification: \"All firms meeting the data requirements are then placed into one of ten decile portfolios based on this ranking, where portfolio 10 represents the winners (those with the highest past returns) and portfolio 1 the losers.\" This means the stocks are evenly divided into different deciles. For example, if we have 20 stocks and one stock had the 2nd best returns and another stock had the 10th best returns, we would place them into deciles 1 and 5, respectively. \n",
    "\n",
    "The portfolios used in Ken French's (KRF) data library were formed in a manner largely consistent with the decile momentum portfolios in Daniel and Moskowitz. The biggest difference was that the portfolio breakpoints for the KRF portfolios were set so that each of the portfolios has an equal number of NYSE firms (sharecode = 1). This means we filtered for stocks in the NYSE firms and evenly sorted them out into deciles 1 through 10. I used this sorting to define the new boundaries and set the remaining firms according to this boundary. Every month-year-stock has two different decile rankings for both the DM portfolio and the KRF portfolio. These deciles are usually the same for each stock, but could differ by one (or more) deciles for a given month-year-stock. For example, stocks in 1927 were almost entirely NYSE stocks, so the two ranking systems were mostly the same. As time progressed, however, the other exchanges became more prominent and the two decile ranking systems could differ significantly from one another.\n",
    "\n",
    "One reason we want to divide all stocks based on the NYSE stocks is because the NYSE is a simple measure to include largely traded stocks. If our bottom portfolio contained no NYSE stocks, it could skew our portfolio and increase risk with many low cap, less traded stocks. This method is a good way to ensure the portfolio is more easily constructable.\n",
    "\n",
    "The final output of our decile_ranking function is from 1927-2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "170d5c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decile_ranking(df):\n",
    "    \n",
    "    # Create final_df to store all of our values from each month and year\n",
    "    final_df = pd.DataFrame()\n",
    "    \n",
    "    # First let's create a list containing our dates, so we can find the last 13 months of data for momentum\n",
    "    date = df[['year', 'month']].drop_duplicates().sort_values(by=['year', 'month'])\n",
    "    \n",
    "    # Iterate through all available year-months for stock data\n",
    "    for index, row in date.iterrows():\n",
    "        \n",
    "        year = row['year']\n",
    "        month = row['month']\n",
    "            \n",
    "        # Create dataframe of all stocks for this specific month and date\n",
    "        all_stocks = df[(df['year'] == year) & (df['month'] == month)].copy()\n",
    "\n",
    "        # Create dataframe of all NYSE stocks for this specific month and date\n",
    "        nyse = df[(df['year'] == year) & (df['month'] == month) & (df['exchcd'] == 1)].copy()\n",
    "        \n",
    "        # Ensure nyse has enough stocks to sort data\n",
    "        if (len(nyse) >= 10):\n",
    "        \n",
    "            # Get ranges for the Ranking_Ret quartiles\n",
    "            nyse['quartile'] = pd.qcut(nyse['ranking_ret'], q=10, labels=False)\n",
    "            quartile_ranges = nyse.groupby('quartile')['ranking_ret'].agg(['min', 'max'])\n",
    "            \n",
    "            # Increase max index to unbounded so we do not leave any stocks behind\n",
    "            quartile_ranges.iloc[9, 1] = np.inf\n",
    "            quartile_ranges += 1\n",
    "            stock_bins = [0] + quartile_ranges['max'].tolist()\n",
    "\n",
    "            # Map ranges to all stocks giving us the KRF_decile\n",
    "            all_stocks['krf_decile'] = pd.cut(all_stocks['ranking_ret'], bins=stock_bins, labels=range(0, 10), include_lowest=True)\n",
    "            all_stocks['dm_decile'] = pd.cut(all_stocks['ranking_ret'], bins=10, labels=False)\n",
    "            \n",
    "            # Add one to the deciles to match the D&M Paper format\n",
    "            all_stocks['krf_decile'] = all_stocks['krf_decile'].astype(int) + 1\n",
    "            all_stocks['dm_decile'] = all_stocks['dm_decile'].astype(int) + 1\n",
    "            \n",
    "            # Reorder columns into desired format\n",
    "            all_stocks = all_stocks[['year', 'month', 'permno', 'lme', 'ret', 'dm_decile', 'krf_decile', 'exchcd']]\n",
    "            final_df = pd.concat([final_df, all_stocks])\n",
    "        \n",
    "    return(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ec7e9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = decile_ranking(a1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9421f066",
   "metadata": {},
   "source": [
    "The below monthly_decile_returns function uses the lagged market cap and returns to find the value-weighted return on each portfolio decile for each year-month. We then end up with 10 different returns for each month of our data. I start by filtering for stocks in a specific month, year and decile. Next, I find the total lagged market cap and then the realized return. I divide the total return by total market cap to find out return for that month. From the output dataframe, we see a high correlation between decile and return, with the higher decile typically corresponding to a higher return. \n",
    "\n",
    "Our output is from 1927-2023 and the columns 'dm_ret' and 'krf_ret' show total return and not excess return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb175cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_decile_returns(stock_ranking, french):\n",
    "    \n",
    "    # Create lists for our final dataframe\n",
    "    years = []\n",
    "    months = []\n",
    "    deciles = []\n",
    "    dm_rets = []\n",
    "    krf_rets = []\n",
    "    rfs = []\n",
    "    \n",
    "    # Create list of deciles to iterate through\n",
    "    decile_list = [1,2,3,4,5,6,7,8,9,10]\n",
    "    \n",
    "    # Find all unique year-month combinations present in both stocks and french\n",
    "    momentum_date = stock_ranking[['year', 'month']].drop_duplicates().sort_values(by=['year', 'month'])\n",
    "    french_date = french[['year', 'month']].drop_duplicates().sort_values(by=['year', 'month'])\n",
    "    date = french_date.merge(momentum_date, how='inner', on=['year', 'month'])\n",
    "\n",
    "    # Iterate over the DataFrame and print year and month\n",
    "    for index, row in date.iterrows():\n",
    "        # Find monthly returns\n",
    "        year = row['year']\n",
    "        month = row['month']\n",
    "        this_month = stock_ranking[(stock_ranking['year'] == year) & (stock_ranking['month'] == month)].copy()\n",
    "            \n",
    "        for i in decile_list:\n",
    "            # Create decile list for both portfolios\n",
    "            dm_decile = this_month[this_month['dm_decile'] == i].copy()\n",
    "            krf_decile = this_month[this_month['krf_decile'] == i].copy()\n",
    "\n",
    "            # Calculate DM returns for specific Year-Month-Decile\n",
    "            dm_last_month_value = dm_decile['lme'].sum()\n",
    "            dm_this_month_value = (dm_decile['lme']*(1 + dm_decile['ret'])).sum()\n",
    "            dm_ret = (dm_this_month_value - dm_last_month_value)/dm_last_month_value\n",
    "\n",
    "            # Calculate KRF returns for specific Year-Month_Decile\n",
    "            krf_last_month_value = krf_decile['lme'].sum()\n",
    "            krf_this_month_value = (krf_decile['lme']*(1 + krf_decile['ret'])).sum()\n",
    "            krf_ret = (krf_this_month_value - krf_last_month_value)/krf_last_month_value\n",
    "            \n",
    "            # Calculate risk free rates\n",
    "            rf = french[(french['year'] == year) & (french['month'] ==  month)]['rf'].iloc[0]\n",
    "\n",
    "            # Append all of our data for our new dataframe\n",
    "            years.append(year)\n",
    "            months.append(month)\n",
    "            deciles.append(i)\n",
    "            dm_rets.append(dm_ret)\n",
    "            krf_rets.append(krf_ret)\n",
    "            rfs.append(rf)\n",
    "                \n",
    "    data = {\n",
    "    'year': years,\n",
    "    'month': months,\n",
    "    'decile': deciles,\n",
    "    'dm_ret': dm_rets,\n",
    "    'krf_ret': krf_rets,\n",
    "    'rf': rfs}\n",
    "\n",
    "    final_df = pd.DataFrame(data)\n",
    "\n",
    "    return(final_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0472c002",
   "metadata": {},
   "outputs": [],
   "source": [
    "a3 = monthly_decile_returns(a2, french)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acf4d29",
   "metadata": {},
   "source": [
    "In the below generate_dm_table function, I am recreating the data table shown on the Daniel Moskowitz paper. I utilize our dataframe output from monthly_decile_returns as the input since this contains each year-month-decile plus the risk free rate. We can then filter our dataframe for each specific decile and find the average monthly return. We convert from monthly return to annualized return using the formula below:\n",
    "\n",
    "$$\n",
    "r_{annual} = 12*r_{monthly}\n",
    "$$\n",
    "\n",
    "And from monthly standard deviation to annualized standard deviation using the formula below:\n",
    "\n",
    "$$\n",
    "\\sigma_{annual} = \\sqrt{12}*\\sigma_{monthly}\n",
    "$$\n",
    "\n",
    "The sk(m) column is the full-period realized skewness of the monthly log returns (not excess) to the portfolios. We used the below formula for this:\n",
    "\n",
    "$$\n",
    "R_t = ln\\big(\\frac{P_t}{P_{t-1}}\\big)\n",
    "$$\n",
    "\n",
    "The WML portfolio can be viewed as the zero initial value long-short portfolio that shorts decile 1 and invests that money into decile 10. \n",
    "\n",
    "Before we implement the generate_dm_table function, we first need to filter our data frame to achieve the dates in the Daniel and Moskowitz paper. This means we need all year-month-decile data from January 1927 to March 2013. I also import the actual dm returns to find the correlation with our replicated results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0f3f3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a3 = a3[(a3['year'] >= 1927) & ((a3['year'] < 2013) | ((a3['year'] == 2013) & (a3['month'] <= 3)))].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba92a69",
   "metadata": {},
   "source": [
    "The below code uses the 'm_m_pt_tot.txt' file containing the actual year-month-deciles for the DM portfolio. The below code imports the data, converts the date to month and year, rearranges the data per the problem input, and then  splices for the desired dates of the Daniel and Moskowitz paper. We need this data to find the correlation between the DM returns and the replicated returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "824bb255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull data from our txt file\n",
    "df_dm_data = pd.read_csv('m_m_pt_tot.txt', header=None, sep='\\s+', names=['date', 'decile', 'DM_Ret_actual', 'd', 'e'])\n",
    "\n",
    "# Convert 'date' column to month and year\n",
    "df_dm_data['year'] = df_dm_data['date'].apply(lambda x: int(str(x)[:4]))\n",
    "df_dm_data['month'] = df_dm_data['date'].apply(lambda x: int(str(x)[4:6]))\n",
    "df_dm_data = df_dm_data.rename(columns = {'DM_Ret_actual': 'dm_ret_actual'})\n",
    "\n",
    "# Rearrange columns\n",
    "df_dm_data = df_dm_data[['year', 'month', 'decile', 'dm_ret_actual']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86aa070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dm_table(decile_returns, dm_actual):\n",
    "    \n",
    "    # Merge df1 and df2 for simplicity for each year-month-decile\n",
    "    df = pd.merge(decile_returns, dm_actual, how = 'inner', on = ['year', 'month', 'decile'])\n",
    "    decile_returns = []\n",
    "    sds = []\n",
    "    SRs = []\n",
    "    sk_ms = []\n",
    "    correlations = []\n",
    "    \n",
    "    # Iterate through the 10 different deciles\n",
    "    for i in range(1,11):\n",
    "        \n",
    "        # Calculate average annual excess return\n",
    "        this_decile_return = 1200*(df[df['decile'] == i]['dm_ret'] - df[df['decile'] == i]['rf']).mean()\n",
    "        \n",
    "        # Calculate average annual standard deviation\n",
    "        sd = 100*np.sqrt(12)*(df[df['decile'] == i]['dm_ret'] - df[df['decile'] == i]['rf']).std()\n",
    "        \n",
    "        # Calculate average annual Sharpe Ratio\n",
    "        SR = this_decile_return/sd\n",
    "        \n",
    "        # Calculate average sk(m)\n",
    "        sk_m = (np.log(df[df['decile'] == i]['dm_ret'] + 1)).skew()\n",
    "        \n",
    "        # Calculate correlation between replicated and actual datasets\n",
    "        correlation = df[df['decile'] == i]['dm_ret'].corr(df[df['decile'] == i]['dm_ret_actual'])\n",
    "        \n",
    "        # Append our results to each respective list\n",
    "        decile_returns.append(this_decile_return)\n",
    "        sds.append(sd)\n",
    "        SRs.append(SR)\n",
    "        sk_ms.append(sk_m)\n",
    "        correlations.append(correlation)\n",
    "\n",
    "    # Compute WML metrics, using same methods as above\n",
    "    W = df[df['decile'] == 10]['dm_ret'].reset_index(drop=True)\n",
    "    L = df[df['decile'] == 1]['dm_ret'].reset_index(drop=True)\n",
    "    WML_ret = 1200*(W - L).mean()\n",
    "    WML_std = 100*np.sqrt(12)*(W - L).std()\n",
    "    WML_SR = WML_ret/WML_std\n",
    "    WML_skm = (np.log(W - L + 1)).skew()\n",
    "    WML_corr = (W - L).reset_index(drop=True).corr(df[df['decile'] == 10]['dm_ret_actual'].reset_index(drop=True) - df[df['decile'] == 1]['dm_ret_actual'].reset_index(drop=True))\n",
    "\n",
    "    # Append WML to lists\n",
    "    decile_returns.append(WML_ret)\n",
    "    sds.append(WML_std)\n",
    "    SRs.append(WML_SR)\n",
    "    sk_ms.append(WML_skm)\n",
    "    correlations.append(WML_corr)\n",
    "    \n",
    "    # Construct our new data frame as our output\n",
    "    data = {\n",
    "    'deciles': ['decile 1', 'decile 2', 'decile 3', 'decile 4', 'decile 5', 'decile 6', 'decile 7', 'decile 8', 'decile 9', 'decile 10', 'wml'],\n",
    "    '$r - r_f$': decile_returns,\n",
    "    'σ': sds,\n",
    "    'SR': SRs,\n",
    "    'sk(m)': sk_ms,\n",
    "    'correlations': correlations\n",
    "    }\n",
    "\n",
    "\n",
    "    final_df = pd.DataFrame(data)\n",
    "    return(final_df.round(2).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf9deaa",
   "metadata": {},
   "source": [
    "In the below table, we can see our replicated Daniel and Moskowitz data for January 1926 to March 2013. While that data is not an exact replication and can be off by as much as a percent for some of the deciles, the general trends in the replication portfolio are extremely similar to the paper. We can see that we typically have a strong correlation of around 95\\% to 97\\%. We also see extremely strong trends and a general increase as we move from decile 1 to decile 10. The WML long-short portfolio return was found to be 17.23\\%, showing the \"magic\" of the momentum portfolio. \n",
    "\n",
    "One of the reasons the correlations are not perfect would be because I required stocks to be consistently listed for 13 months straight. Some of the Daniel and Moskowitz stocks could have only existied for 8 months out of the 13 months and still be included in the DM portfolio. I thought my method was easier to implement, more realistic and would not bring up several NaN erros in the code. Plus with my method, we gain a more comprehensive picture of the stock momentum directions.\n",
    "\n",
    "Another possible reason for not obtaining exact replication is my choosing stocks that only exist on the NYSE, AMEX and NASDAQ. Daniel and Moskowitz could have considered stocks from other exchanges or countries. There is also a possibility of them using other methods unspecified in their paper when constructing these momentum portfolios. Regardless of not obtaining the exact numbers, we still achieved a very high correlation that shows the power of a momentum portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a95c820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Average Annual DM Momentum Portfolio metrics from January 1927 to March 2013\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deciles</th>\n",
       "      <td>decile 1</td>\n",
       "      <td>decile 2</td>\n",
       "      <td>decile 3</td>\n",
       "      <td>decile 4</td>\n",
       "      <td>decile 5</td>\n",
       "      <td>decile 6</td>\n",
       "      <td>decile 7</td>\n",
       "      <td>decile 8</td>\n",
       "      <td>decile 9</td>\n",
       "      <td>decile 10</td>\n",
       "      <td>wml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$r - r_f$</th>\n",
       "      <td>-1.23</td>\n",
       "      <td>2.56</td>\n",
       "      <td>3.84</td>\n",
       "      <td>6.26</td>\n",
       "      <td>7.49</td>\n",
       "      <td>7.41</td>\n",
       "      <td>9.38</td>\n",
       "      <td>10.68</td>\n",
       "      <td>11.82</td>\n",
       "      <td>15.59</td>\n",
       "      <td>16.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>σ</th>\n",
       "      <td>33.61</td>\n",
       "      <td>26.96</td>\n",
       "      <td>23.6</td>\n",
       "      <td>21.41</td>\n",
       "      <td>20.5</td>\n",
       "      <td>19.53</td>\n",
       "      <td>19.7</td>\n",
       "      <td>20.46</td>\n",
       "      <td>21.69</td>\n",
       "      <td>26.76</td>\n",
       "      <td>28.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR</th>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sk(m)</th>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>-5.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correlations</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0         1         2         3         4         5   \\\n",
       "deciles       decile 1  decile 2  decile 3  decile 4  decile 5  decile 6   \n",
       "$r - r_f$        -1.23      2.56      3.84      6.26      7.49      7.41   \n",
       "σ                33.61     26.96      23.6     21.41      20.5     19.53   \n",
       "SR               -0.04      0.09      0.16      0.29      0.37      0.38   \n",
       "sk(m)            -0.15      -0.1     -0.04     -0.12     -0.29     -0.53   \n",
       "correlations      0.97      0.97      0.97      0.96      0.97      0.96   \n",
       "\n",
       "                    6         7         8          9      10  \n",
       "deciles       decile 7  decile 8  decile 9  decile 10    wml  \n",
       "$r - r_f$         9.38     10.68     11.82      15.59  16.83  \n",
       "σ                 19.7     20.46     21.69      26.76  28.28  \n",
       "SR                0.48      0.52      0.54       0.58    0.6  \n",
       "sk(m)            -0.53     -0.45     -0.58      -0.88  -5.49  \n",
       "correlations      0.97      0.96      0.97       0.97   0.91  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a4 = generate_dm_table(a3, df_dm_data)\n",
    "print('    Average Annual DM Momentum Portfolio metrics from January 1927 to March 2013')\n",
    "a4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe49397",
   "metadata": {},
   "source": [
    "The below generate_krf_table function will do the same as the generate_dm_table function except it uses the 'krf_ret' returns instead of the dm_ret. Since the KRF returns utilized a different method from what Daniel and Moskowitz used to construct their portfolio, we observe it to have a lower correlation than our DM replication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0114bc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_krf_table(decile_returns, dm_actual):\n",
    "    \n",
    "    # Merge df1 and df2 for simplicity\n",
    "    df = pd.merge(decile_returns, dm_actual, how = 'inner', on =['year', 'month', 'decile'])\n",
    "    decile_returns = []\n",
    "    sds = []\n",
    "    SRs = []\n",
    "    sk_ms = []\n",
    "    correlations = []\n",
    "    for i in range(1,11):\n",
    "        this_decile_return = 1200*(df[df['decile'] == i]['krf_ret'] - df[df['decile'] == i]['rf']).mean()\n",
    "        sd = 100*np.sqrt(12)*(df[df['decile'] == i]['krf_ret'] - df[df['decile'] == i]['rf']).std()\n",
    "        SR = this_decile_return/sd\n",
    "        sk_m = (np.log(df[df['decile'] == i]['krf_ret'] + 1)).skew()\n",
    "        correlation = df[df['decile'] == i]['krf_ret'].corr(df[df['decile'] == i]['dm_ret_actual'])\n",
    "        # Append our results to each respective list\n",
    "        decile_returns.append(this_decile_return)\n",
    "        sds.append(sd)\n",
    "        SRs.append(SR)\n",
    "        sk_ms.append(sk_m)\n",
    "        correlations.append(correlation)\n",
    "\n",
    "    # Compute WML metrics\n",
    "    W = df[df['decile'] == 10]['krf_ret'].reset_index(drop=True)\n",
    "    L = df[df['decile'] == 1]['krf_ret'].reset_index(drop=True)\n",
    "    WML_ret = 1200*(W - L).mean()\n",
    "    WML_std = 100*np.sqrt(12)*(W - L).std()\n",
    "    WML_SR = WML_ret/WML_std\n",
    "    WML_skm = (np.log(W - L + 1)).skew()\n",
    "    WML_corr = (W - L).reset_index(drop=True).corr(df[df['decile'] == 10]['dm_ret_actual'].reset_index(drop=True) - df[df['decile'] == 1]['dm_ret_actual'].reset_index(drop=True))\n",
    "\n",
    "    # Append WML to lists\n",
    "    decile_returns.append(WML_ret)\n",
    "    sds.append(WML_std)\n",
    "    SRs.append(WML_SR)\n",
    "    sk_ms.append(WML_skm)\n",
    "    correlations.append(WML_corr)\n",
    "    \n",
    "    data = {\n",
    "    'deciles': ['decile 1', 'decile 2', 'decile 3', 'decile 4', 'decile 5', 'decile 6', 'decile 7', 'decile 8', 'decile 9', 'decile 10', 'wml'],\n",
    "    '$r - r_f$': decile_returns,\n",
    "    'σ': sds,\n",
    "    'SR': SRs,\n",
    "    'sk(m)': sk_ms,\n",
    "    'correlations': correlations\n",
    "    }\n",
    "\n",
    "    final_df = pd.DataFrame(data)\n",
    "    return(final_df.round(2).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d25bd4e",
   "metadata": {},
   "source": [
    "From the table below, we can see we do not achieve as high of a WML return compared to the Daniel and Moskowitz portfolio construction. We should note, however, that this WML has a smaller annual standard deviation (around 3\\% less). This makes intuitive sense since we could consider the NYSE stocks to be larger cap and slightly more stable. The means the KRF portfolio is less likely to have many lower cap, higher risk, non NYSE stocks to compose our loser portion of the portfolio, making the KRF decile 1 less risky. So while the KRF portfolio does not achieve returns as high as the DM portfolio, it likely performs better than the DM portfolio during market downturns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae7032d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Average Annual KRF Momentum Portfolio metrics from January 1927 to March 2013\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deciles</th>\n",
       "      <td>decile 1</td>\n",
       "      <td>decile 2</td>\n",
       "      <td>decile 3</td>\n",
       "      <td>decile 4</td>\n",
       "      <td>decile 5</td>\n",
       "      <td>decile 6</td>\n",
       "      <td>decile 7</td>\n",
       "      <td>decile 8</td>\n",
       "      <td>decile 9</td>\n",
       "      <td>decile 10</td>\n",
       "      <td>wml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$r - r_f$</th>\n",
       "      <td>0.69</td>\n",
       "      <td>4.86</td>\n",
       "      <td>5.32</td>\n",
       "      <td>6.65</td>\n",
       "      <td>7.02</td>\n",
       "      <td>7.71</td>\n",
       "      <td>8.85</td>\n",
       "      <td>10.45</td>\n",
       "      <td>11.03</td>\n",
       "      <td>14.75</td>\n",
       "      <td>14.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>σ</th>\n",
       "      <td>31.26</td>\n",
       "      <td>25.83</td>\n",
       "      <td>22.68</td>\n",
       "      <td>20.85</td>\n",
       "      <td>20.22</td>\n",
       "      <td>19.57</td>\n",
       "      <td>19.33</td>\n",
       "      <td>19.98</td>\n",
       "      <td>20.64</td>\n",
       "      <td>25.04</td>\n",
       "      <td>25.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sk(m)</th>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-1.04</td>\n",
       "      <td>-5.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correlations</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0         1         2         3         4         5   \\\n",
       "deciles       decile 1  decile 2  decile 3  decile 4  decile 5  decile 6   \n",
       "$r - r_f$         0.69      4.86      5.32      6.65      7.02      7.71   \n",
       "σ                31.26     25.83     22.68     20.85     20.22     19.57   \n",
       "SR                0.02      0.19      0.23      0.32      0.35      0.39   \n",
       "sk(m)             0.02     -0.08      0.02     -0.06     -0.32     -0.55   \n",
       "correlations      0.96      0.95      0.95      0.94      0.95      0.96   \n",
       "\n",
       "                    6         7         8          9      10  \n",
       "deciles       decile 7  decile 8  decile 9  decile 10    wml  \n",
       "$r - r_f$         8.85     10.45     11.03      14.75  14.06  \n",
       "σ                19.33     19.98     20.64      25.04   25.4  \n",
       "SR                0.46      0.52      0.53       0.59   0.55  \n",
       "sk(m)            -0.48     -0.51     -0.58      -1.04  -5.57  \n",
       "correlations      0.96      0.96      0.97       0.97   0.88  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a5 = generate_krf_table(a3, df_dm_data)\n",
    "print('    Average Annual KRF Momentum Portfolio metrics from January 1927 to March 2013')\n",
    "a5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5769804f",
   "metadata": {},
   "source": [
    "## Would you implement this trading strategy if you were running your own fund? What are the main implementation challenges to consider?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4532b83b",
   "metadata": {},
   "source": [
    "While the momentum trading strategies like the DM portfolio we constructed above tend to produce returns well in excess of the average market return, we have to be aware of this strategy's risks before we invest in such a portfolio. One such risk is a high standard deviation as we saw on our final tables. The DM annualized standard deviation was around 28\\%, which is slightly higher than the average market annualized standard deviation. We also saw from the graph above the higher potential for bad returns when compared to an unleveraged portfolio. This contributes to a much higher value at risk than other portfolios such as the 60-40 stock bond portfolio we constructed earlier. \n",
    "\n",
    "Personally, I would implement this WML portfolio as a trading strategy since the exceptional returns seem to outweigh the potentially large downsides. Before adopting this trading method, however, I would spend considerable time studying historical data to determine trends in momentum. One such trend that is likely to appear is the WML portfolio relationship to the VIX index, with a higher VIX score corresponding to higher losses on the WML portfolio, on average. This is due to the momentum portfolio failing during market downturns. \n",
    "\n",
    "Considering just data from 1963 to 2023, the worst months during this time period for the momentum portfolios were:\n",
    "\n",
    "1.\tApril 2009:\t-34.3%\t\n",
    "\n",
    "2.\tJanuary 2001:\t-25.3%\t\n",
    "\n",
    "3.\tNovember 2002:\t-16.3%\t\n",
    "\n",
    "4.\tJanuary 2023:\t-16.0%\n",
    "\n",
    "5.\tJanuary 1975:\t-13.8%\n",
    "\n",
    "6.\tMay 2009:       -12.5%\t\n",
    "\n",
    "7.\tNovember 2020:\t-12.4%\t\n",
    "\n",
    "\n",
    "Using the historical value at risk method, this corresponds to a 99% VaR of -12.4% for our WML portfolio. We would therefore need to be comfortable with this VaR number before proceeding with the WML method. If we were investing client's money, they would need to be aware of this strategy's upsides and risks.\n",
    "\n",
    "Other strategies to implement would be avoiding using the momentum strategy during market downturns. We can see in the list above that this strategy did poorly during the 2009 crash as well as the internet bubble. If we can find a way to not use this strategy during these periods of high volatility, we have a better chance of achieving good returns for the WML portfolio and avoiding the months with huge losses.\n",
    "\n",
    "Other things to consider for this portfolio is if the WML will continue to work into the future. It typically does well when growth stocks do well. Lately the growth stocks have been mainly driven by tech. If tech begins to do poorly and value stocks tend to do better, we could see some sort of mean reversion. In the case of a mean reversion, this portfolio will perform poorly. \n",
    "\n",
    "To sum up, the WML strategy is a remarkable \"magic\" strategy that achieves returns higher on average than the market returns. It comes with its own risks and tends to have very bad months that can result in huge losses. We need to be fully aware of the risks and proceed with caution before pursing this trading strategy. If implemented for a long enough time, the returns tend to be very good."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
